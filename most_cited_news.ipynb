{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1e593-b483-45f8-b8dd-ae041e19c02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.auto import trange, tqdm\n",
    "import time\n",
    "from journal_API_wikidata import extract_info_wiki\n",
    "from Data_clean_functions import *\n",
    "from tld import get_tld\n",
    "DATA_PATH = './Data/'\n",
    "FILE = DATA_PATH + 'quotes-2019.json.bz2'\n",
    "PATH_OUT = DATA_PATH + 'rapid_clean-quotes-2019.json.bz2'\n",
    "PATH_OUT_filter = DATA_PATH + 'filter_clean-quotes-2019.json.bz2'\n",
    "# Download it from the drive and add to your folder / adapt path\n",
    "PATH_WIKIDATA_UTILS = DATA_PATH + 'Wikidata_utils.pkl' \n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63e1fc-2ad4-45b9-af51-acb37d74b198",
   "metadata": {},
   "source": [
    "### Do basic data cleaning and count occurrences of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791a39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pickle the chunks of dataframe for later\n",
    "n_chunks = 0\n",
    "Total_count = Counter()\n",
    "top_sites = []\n",
    "\n",
    "with pd.read_json(FILE, lines=True, compression='bz2', chunksize=100000) as df_reader:\n",
    "    for chunk in tqdm(df_reader):\n",
    "\n",
    "        df_base_clean = rapid_clean(chunk)\n",
    "        # Extract site name from dataframe\n",
    "        extract_name(df_base_clean)\n",
    "        \n",
    "        df_base_clean_exp = df_base_clean.explode([\"sitenames\", \"urls\"])\n",
    "        with open(PATH_OUT, 'ab') as d_file:\n",
    "            pickle.dump(df_base_clean_exp, d_file)\n",
    "            n_chunks += 1\n",
    "            \n",
    "        counts = Counter(df_base_clean_exp['sitenames'].tolist()) \n",
    "        Total_count += counts\n",
    "        print(\"Chunk done\")\n",
    "   \n",
    "    for site, count in Total_count.most_common(100):\n",
    "            top_sites.append(site)\n",
    "            \n",
    "\n",
    "    \n",
    "print(\"finished top sites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a8d0fe",
   "metadata": {},
   "source": [
    "### Filter and keep only quotes from top k sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd659a0-65ac-4659-8890-c08c80c3a490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(top_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff06bd8-0975-4696-ba6c-7007b8ca295b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pickle save the top_sites for future use\n",
    "\n",
    "with open(DATA_PATH + 'top_sites.pkl', 'wb') as output:\n",
    "    pickle.dump(top_sites, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22fcf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pickle open the top_sites\n",
    "\n",
    "with open(DATA_PATH + 'top_sites.pkl', 'rb') as file:\n",
    "    top_sites_unpkl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291bb547",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(top_sites_unpkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e0cc2-fd71-4a3a-871a-dc24c684c404",
   "metadata": {},
   "source": [
    "If the next cell too slow, we can always diminish the number of top sites :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ff7ee-115e-4406-b8aa-564fd4486a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_10_sites = top_sites_unpkl[:10]\n",
    "top_10_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab6914-16ba-438f-9dfd-cec6b7af7ae9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunks_all_filtered = pd.DataFrame(columns=['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
    "       'probas', 'urls', 'phase', 'sitenames'])\n",
    "chunk_nbr = 0\n",
    "n_chunks_filtered = 0\n",
    "\n",
    "with open(PATH_OUT, 'rb') as d_file:\n",
    "    while (chunk_nbr < n_chunks):\n",
    "        print(f\"{chunk_nbr}/{n_chunks}\")\n",
    "        chunk = pickle.load(d_file)\n",
    "        chunk_filtered = chunk[chunk.sitenames.isin(top_10_sites)]\n",
    "        \n",
    "        # delete PATH_OUT_filter !!!!!\n",
    "        # delete thefile or change name\n",
    "        with open(PATH_OUT_filter, 'ab') as d_file_out:\n",
    "            pickle.dump(chunk_filtered, d_file_out)\n",
    "            n_chunks_filtered += 1\n",
    "        chunks_all_filtered = chunks_all_filtered.append(chunk_filtered)\n",
    "\n",
    "        chunk_nbr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle for future use\n",
    "\n",
    "with open(DATA_PATH + 'chunks_all_filtered.pkl', 'wb') as output:\n",
    "    pickle.dump(chunks_all_filtered, output)\n",
    "    \n",
    "'''# Open pickled dataframe\n",
    "with open(DATA_PATH + 'chunks_all_filtered.pkl', 'rb') as output:\n",
    "    chunks_all_filtered_unpkl = pickle.load(output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c3e4d-38a3-4472-98d1-03501449b6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_all_filtered = chunks_all_filtered[[\"speaker\", \"qids\" , \"urls\", \"quoteID\", \"quotation\",\"date\"]].groupby([\"speaker\", \"qids\", \"quoteID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7da2a4-1b8b-424b-8e86-a0b130054f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filtered = gb_all_filtered[\"urls\"].apply(list)\n",
    "df_filtered_final = df_filtered.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6f899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'df_filtered_final.pkl', 'wb') as output:\n",
    "    pickle.dump(df_filtered_final, output)\n",
    "    \n",
    "'''# Open pickled dataframe\n",
    "with open(DATA_PATH + 'df_filtered_final.pkl', 'rb') as output:\n",
    "    df_filtered_unpkl = pickle.load(output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d615f15-45a3-495e-93dd-50522b673e5f",
   "metadata": {},
   "source": [
    "### Create a dictionnary of categories and associated synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13416c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matchers = {\"art\": [\"art\", \"paint\", \"draw\", \"museum\"], \\\n",
    "            \"business\": [\"business\", \"finance\", \"economy\", \"commerce\", \"bank\", \"money\", \"trade\"], \\\n",
    "            \"entertainment\":[\"entertainment\"], \n",
    "            \"fashion\":[\"fashion\", \"couture\", \"designer\"], \\\n",
    "            \"medicine\":[\"medicine\", \"health\", \"pharmacy\", \"wellbeing\", \"body\"], \\\n",
    "            \"music\":[\"music\", \"song\", \"album\", \"concert\"], \\\n",
    "            \"politics\":[\"politics\", \"government\"], \\\n",
    "            \"science\":[\"science\", \"research\"], \\\n",
    "            \"sport\": [\"sport\", \"football\", \"athletics\", \"swimming\", \"rugby\", \"tennis\", \"volleyball\", \"ski\"]}\n",
    "\n",
    "# Find general form for categories and words\n",
    "generalizeDictionary(matchers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf71b6",
   "metadata": {},
   "source": [
    "### Extract information from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3afa2-ec5e-4a15-91aa-c21fec8b1880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_extract = Chunk_url_extract(df_filtered_final, matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'df_extract.pkl', 'wb') as output:\n",
    "    pickle.dump(df_extract, output)\n",
    "    \n",
    "'''# Open pickled dataframe\n",
    "with open(DATA_PATH + 'df_extract.pkl', 'rb') as output:\n",
    "    df_extract_unpkl = pickle.load(output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05214a",
   "metadata": {},
   "source": [
    "### Add information from wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file \n",
    "\n",
    "with open(PATH_WIKIDATA_UTILS, 'rb') as input_file:\n",
    "    Wikidata_utils = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb2c18-aae8-4523-a764-b701dcf0d4ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2019 = merge_quotes_wikidata(Wikidata_utils, df_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'df_2019_no_media.pkl', 'wb') as output:\n",
    "    pickle.dump(df_2019, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
