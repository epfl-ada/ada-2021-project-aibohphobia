{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-stereo",
   "metadata": {},
   "source": [
    "##### (Skeleton using chunks)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abroad-steel",
   "metadata": {},
   "source": [
    "def process_chunk(chunk):\n",
    "        print(f'Processing chunk with {len(chunk)} rows')\n",
    "\n",
    "with pd.read_json(FILE2016, lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        process_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-unemployment",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "under-prevention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './Data/'\n",
    "FILE2016 = DATA_PATH + 'quotes-2020.json.bz2'\n",
    "df_base = pd.read_json(FILE2016, lines=True, compression='bz2', nrows=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-friendship",
   "metadata": {},
   "source": [
    "### Create a copy to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cheap-theta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28-000082</td>\n",
       "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-01-28 08:04:05</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.7272], [Prime Minister Netanyahu, 0....</td>\n",
       "      <td>[http://israelnationalnews.com/News/News.aspx/...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
       "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-10-000142</td>\n",
       "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-10 23:45:54</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.8926], [Prakash Rai, 0.1074]]</td>\n",
       "      <td>[https://indianexpress.com/article/business/ec...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-15-000053</td>\n",
       "      <td>... [ I ] f it gets to the floor,</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-15 14:12:51</td>\n",
       "      <td>2</td>\n",
       "      <td>[[None, 0.581], [Andy Harris, 0.4191]]</td>\n",
       "      <td>[https://patriotpost.us/opinion/68622-trump-bu...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
       "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2020-03-02-078576</td>\n",
       "      <td>Why now, 2021? Here's why,</td>\n",
       "      <td>Michael J. Graham</td>\n",
       "      <td>[Q6831418]</td>\n",
       "      <td>2020-03-02 21:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Michael J. Graham, 0.6261], [None, 0.3739]]</td>\n",
       "      <td>[https://thecourier.com/ohio-news/2020/03/02/p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2020-04-14-074488</td>\n",
       "      <td>Why should a running back be treated less than...</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>[Q452154]</td>\n",
       "      <td>2020-04-14 22:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Mark Ingram, 0.5275], [None, 0.4657], [Chris...</td>\n",
       "      <td>[http://registercitizen.com/sports/article/Ing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2020-04-15-078413</td>\n",
       "      <td>Why would I leave here where I'm healthy, to t...</td>\n",
       "      <td>Pauline Pearce</td>\n",
       "      <td>[Q55076551]</td>\n",
       "      <td>2020-04-15 10:10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pauline Pearce, 0.8222], [None, 0.1778]]</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-england-london-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2020-01-18-055386</td>\n",
       "      <td>Will he be back? And if so, will it be with th...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-01-18 05:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.8911], [Tom Brady, 0.0929], [Logan R...</td>\n",
       "      <td>[http://www.mywebtimes.com/2020/01/14/full-cou...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2020-03-26-086246</td>\n",
       "      <td>will not be the first commissioner of an Ameri...</td>\n",
       "      <td>Adam Silver</td>\n",
       "      <td>[Q4679786]</td>\n",
       "      <td>2020-03-26 22:20:01</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Adam Silver, 0.5877], [None, 0.3937], [Jay M...</td>\n",
       "      <td>[http://sportsbusinessdaily.com/Daily/Issues/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-28-000082  [ D ] espite the efforts of the partners to cr...   \n",
       "1     2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "2     2020-02-10-000142  ... He (Madhav) also disclosed that the illega...   \n",
       "3     2020-02-15-000053                  ... [ I ] f it gets to the floor,   \n",
       "4     2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "...                 ...                                                ...   \n",
       "9995  2020-03-02-078576                         Why now, 2021? Here's why,   \n",
       "9996  2020-04-14-074488  Why should a running back be treated less than...   \n",
       "9997  2020-04-15-078413  Why would I leave here where I'm healthy, to t...   \n",
       "9998  2020-01-18-055386  Will he be back? And if so, will it be with th...   \n",
       "9999  2020-03-26-086246  will not be the first commissioner of an Ameri...   \n",
       "\n",
       "                  speaker         qids                date  numOccurrences  \\\n",
       "0                    None           [] 2020-01-28 08:04:05               1   \n",
       "1              Sue Myrick    [Q367796] 2020-01-16 12:00:13               1   \n",
       "2                    None           [] 2020-02-10 23:45:54               1   \n",
       "3                    None           [] 2020-02-15 14:12:51               2   \n",
       "4     Meghan King Edmonds  [Q20684375] 2020-01-24 20:37:09               4   \n",
       "...                   ...          ...                 ...             ...   \n",
       "9995    Michael J. Graham   [Q6831418] 2020-03-02 21:03:20               1   \n",
       "9996          Mark Ingram    [Q452154] 2020-04-14 22:03:37               1   \n",
       "9997       Pauline Pearce  [Q55076551] 2020-04-15 10:10:33               1   \n",
       "9998                 None           [] 2020-01-18 05:30:00               1   \n",
       "9999          Adam Silver   [Q4679786] 2020-03-26 22:20:01               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [[None, 0.7272], [Prime Minister Netanyahu, 0....   \n",
       "1     [[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...   \n",
       "2               [[None, 0.8926], [Prakash Rai, 0.1074]]   \n",
       "3                [[None, 0.581], [Andy Harris, 0.4191]]   \n",
       "4     [[Meghan King Edmonds, 0.5446], [None, 0.2705]...   \n",
       "...                                                 ...   \n",
       "9995      [[Michael J. Graham, 0.6261], [None, 0.3739]]   \n",
       "9996  [[Mark Ingram, 0.5275], [None, 0.4657], [Chris...   \n",
       "9997         [[Pauline Pearce, 0.8222], [None, 0.1778]]   \n",
       "9998  [[None, 0.8911], [Tom Brady, 0.0929], [Logan R...   \n",
       "9999  [[Adam Silver, 0.5877], [None, 0.3937], [Jay M...   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://israelnationalnews.com/News/News.aspx/...     E  \n",
       "1     [http://thehill.com/opinion/international/4782...     E  \n",
       "2     [https://indianexpress.com/article/business/ec...     E  \n",
       "3     [https://patriotpost.us/opinion/68622-trump-bu...     E  \n",
       "4     [https://people.com/parents/meghan-king-edmond...     E  \n",
       "...                                                 ...   ...  \n",
       "9995  [https://thecourier.com/ohio-news/2020/03/02/p...     E  \n",
       "9996  [http://registercitizen.com/sports/article/Ing...     E  \n",
       "9997  [https://www.bbc.co.uk/news/uk-england-london-...     E  \n",
       "9998  [http://www.mywebtimes.com/2020/01/14/full-cou...     E  \n",
       "9999  [http://sportsbusinessdaily.com/Daily/Issues/2...     E  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_base.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-competition",
   "metadata": {},
   "source": [
    "### Check uniqueness of the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df.quoteID.is_unique)\n",
    "df = df.drop_duplicates(subset=['quoteID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n",
      "Processing chunk with 1000 rows\n",
      "True \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dbf51e32d873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprocess_chunk_uniqueid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mlines_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/bz2.py\u001b[0m in \u001b[0;36mread1\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/_compression.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_chunk_uniqueid(chunk):\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "    print(chunk.quoteID.is_unique, '\\n')\n",
    "    if not(chunk.quoteID.is_unique):\n",
    "        chunk = chunk.drop_duplicates(subset=['quoteID'], keep='first')\n",
    "\n",
    "with pd.read_json(FILE2016, lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        process_chunk_uniqueid(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broke-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 10000 rows\n",
      "True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_chunk_uniqueid(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-upper",
   "metadata": {},
   "source": [
    "### Remove `Nan` & empty quotes \n",
    "\n",
    "Todo:\n",
    "- Use the isna() and isnull() to check to nan/empty list and remove any true values priting the number it may have removed --> Probs gonna be zero tbh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functioning-senator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['quotation']=='None'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "discrete-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We find {} nan values 0\n"
     ]
    }
   ],
   "source": [
    "# this is to verify the nan values \n",
    "print(\"We find {} nan values\", df[\"quotation\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "funky-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is for empty list\n",
    "df[\"quotation\"].isnull()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "utility-expense",
   "metadata": {},
   "source": [
    "#Not sure how an empty quotes would look like : None, Nan,[], ...?\n",
    "df_quotes = df.drop(df[df['quotation']==Nan].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-covering",
   "metadata": {},
   "source": [
    "### Remove `None` speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-diving",
   "metadata": {},
   "source": [
    "#### Automated using chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fewer-governor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 6575 rows\n",
      "\n",
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 6554 rows\n",
      "\n",
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 6546 rows\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-44c301ddee42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlength_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_chunk_removeNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mlines_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;31m# Make sure that the returned objects have the right index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m             )\n\u001b[1;32m   1081\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_chunk_removeNone(chunk):\n",
    "    tot_length = 0\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "    chunk = chunk.drop(chunk[chunk['speaker']=='None'].index)\n",
    "    chunk = chunk.reset_index(drop=True)\n",
    "    tot_length = tot_length + len(chunk)\n",
    "    print('Length of the chunk is now', len(chunk), 'rows\\n')\n",
    "    return tot_length, chunk\n",
    "    \n",
    "\n",
    "with pd.read_json(FILE2016, lines=True, compression='bz2', chunksize=10000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        length_df = process_chunk_removeNone(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-economy",
   "metadata": {},
   "source": [
    "#### Test over the downloaded dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "seventh-opinion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 6575 rows\n",
      "Length of the chunk is now 6575 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
       "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
       "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[ The delay ] will have an impact [ on Slough ...</td>\n",
       "      <td>Dexter Smith</td>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>2020-01-17 13:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dexter Smith, 0.924], [None, 0.076]]</td>\n",
       "      <td>[http://www.sloughexpress.co.uk/gallery/slough...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[ The scheme ] treats addiction as an illness ...</td>\n",
       "      <td>Barry Coppinger</td>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>2020-04-02 14:18:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Barry Coppinger, 0.9017], [None, 0.0983]]</td>\n",
       "      <td>[http://www.theweek.co.uk/106479/why-police-ar...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[ These ] actions will allow households who ha...</td>\n",
       "      <td>Ben Carson</td>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>2020-03-19 19:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Ben Carson, 0.9227], [None, 0.0773]]</td>\n",
       "      <td>[https://mortgageorb.com/hud-fha-suspend-forec...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6570</th>\n",
       "      <td>2020-02-17-085956</td>\n",
       "      <td>whoever is the interested player,</td>\n",
       "      <td>Hardeep Singh Puri</td>\n",
       "      <td>[Q5655835]</td>\n",
       "      <td>2020-02-17 10:15:26</td>\n",
       "      <td>6</td>\n",
       "      <td>[[Hardeep Singh Puri, 0.9405], [None, 0.0595]]</td>\n",
       "      <td>[https://www.livemint.com/news/india/-air-indi...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>2020-03-02-078576</td>\n",
       "      <td>Why now, 2021? Here's why,</td>\n",
       "      <td>Michael J. Graham</td>\n",
       "      <td>[Q6831418]</td>\n",
       "      <td>2020-03-02 21:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Michael J. Graham, 0.6261], [None, 0.3739]]</td>\n",
       "      <td>[https://thecourier.com/ohio-news/2020/03/02/p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>2020-04-14-074488</td>\n",
       "      <td>Why should a running back be treated less than...</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>[Q452154]</td>\n",
       "      <td>2020-04-14 22:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Mark Ingram, 0.5275], [None, 0.4657], [Chris...</td>\n",
       "      <td>[http://registercitizen.com/sports/article/Ing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>2020-04-15-078413</td>\n",
       "      <td>Why would I leave here where I'm healthy, to t...</td>\n",
       "      <td>Pauline Pearce</td>\n",
       "      <td>[Q55076551]</td>\n",
       "      <td>2020-04-15 10:10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pauline Pearce, 0.8222], [None, 0.1778]]</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-england-london-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>2020-03-26-086246</td>\n",
       "      <td>will not be the first commissioner of an Ameri...</td>\n",
       "      <td>Adam Silver</td>\n",
       "      <td>[Q4679786]</td>\n",
       "      <td>2020-03-26 22:20:01</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Adam Silver, 0.5877], [None, 0.3937], [Jay M...</td>\n",
       "      <td>[http://sportsbusinessdaily.com/Daily/Issues/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6575 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1     2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "2     2020-01-17-000357  [ The delay ] will have an impact [ on Slough ...   \n",
       "3     2020-04-02-000239  [ The scheme ] treats addiction as an illness ...   \n",
       "4     2020-03-19-000276  [ These ] actions will allow households who ha...   \n",
       "...                 ...                                                ...   \n",
       "6570  2020-02-17-085956                  whoever is the interested player,   \n",
       "6571  2020-03-02-078576                         Why now, 2021? Here's why,   \n",
       "6572  2020-04-14-074488  Why should a running back be treated less than...   \n",
       "6573  2020-04-15-078413  Why would I leave here where I'm healthy, to t...   \n",
       "6574  2020-03-26-086246  will not be the first commissioner of an Ameri...   \n",
       "\n",
       "                  speaker         qids                date  numOccurrences  \\\n",
       "0              Sue Myrick    [Q367796] 2020-01-16 12:00:13               1   \n",
       "1     Meghan King Edmonds  [Q20684375] 2020-01-24 20:37:09               4   \n",
       "2            Dexter Smith   [Q5268447] 2020-01-17 13:03:00               1   \n",
       "3         Barry Coppinger   [Q4864119] 2020-04-02 14:18:20               1   \n",
       "4              Ben Carson    [Q816459] 2020-03-19 19:14:00               1   \n",
       "...                   ...          ...                 ...             ...   \n",
       "6570   Hardeep Singh Puri   [Q5655835] 2020-02-17 10:15:26               6   \n",
       "6571    Michael J. Graham   [Q6831418] 2020-03-02 21:03:20               1   \n",
       "6572          Mark Ingram    [Q452154] 2020-04-14 22:03:37               1   \n",
       "6573       Pauline Pearce  [Q55076551] 2020-04-15 10:10:33               1   \n",
       "6574          Adam Silver   [Q4679786] 2020-03-26 22:20:01               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...   \n",
       "1     [[Meghan King Edmonds, 0.5446], [None, 0.2705]...   \n",
       "2                [[Dexter Smith, 0.924], [None, 0.076]]   \n",
       "3           [[Barry Coppinger, 0.9017], [None, 0.0983]]   \n",
       "4                [[Ben Carson, 0.9227], [None, 0.0773]]   \n",
       "...                                                 ...   \n",
       "6570     [[Hardeep Singh Puri, 0.9405], [None, 0.0595]]   \n",
       "6571      [[Michael J. Graham, 0.6261], [None, 0.3739]]   \n",
       "6572  [[Mark Ingram, 0.5275], [None, 0.4657], [Chris...   \n",
       "6573         [[Pauline Pearce, 0.8222], [None, 0.1778]]   \n",
       "6574  [[Adam Silver, 0.5877], [None, 0.3937], [Jay M...   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://thehill.com/opinion/international/4782...     E  \n",
       "1     [https://people.com/parents/meghan-king-edmond...     E  \n",
       "2     [http://www.sloughexpress.co.uk/gallery/slough...     E  \n",
       "3     [http://www.theweek.co.uk/106479/why-police-ar...     E  \n",
       "4     [https://mortgageorb.com/hud-fha-suspend-forec...     E  \n",
       "...                                                 ...   ...  \n",
       "6570  [https://www.livemint.com/news/india/-air-indi...     E  \n",
       "6571  [https://thecourier.com/ohio-news/2020/03/02/p...     E  \n",
       "6572  [http://registercitizen.com/sports/article/Ing...     E  \n",
       "6573  [https://www.bbc.co.uk/news/uk-england-london-...     E  \n",
       "6574  [http://sportsbusinessdaily.com/Daily/Issues/2...     E  \n",
       "\n",
       "[6575 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l, df = process_chunk_removeNone(df)\n",
    "df\n",
    "#don't understand why the output is not of 6575 rows :(\n",
    "\n",
    "# It is not bevause the scope of df is only in the function thus you need to return it :)\n",
    "# See how the function changed now ? \n",
    "# Now it should work, but I wold be very careful using the same name here\n",
    "# If run twice the print text would change ofc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "endless-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
       "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
       "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[ The delay ] will have an impact [ on Slough ...</td>\n",
       "      <td>Dexter Smith</td>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>2020-01-17 13:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dexter Smith, 0.924], [None, 0.076]]</td>\n",
       "      <td>[http://www.sloughexpress.co.uk/gallery/slough...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[ The scheme ] treats addiction as an illness ...</td>\n",
       "      <td>Barry Coppinger</td>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>2020-04-02 14:18:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Barry Coppinger, 0.9017], [None, 0.0983]]</td>\n",
       "      <td>[http://www.theweek.co.uk/106479/why-police-ar...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[ These ] actions will allow households who ha...</td>\n",
       "      <td>Ben Carson</td>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>2020-03-19 19:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Ben Carson, 0.9227], [None, 0.0773]]</td>\n",
       "      <td>[https://mortgageorb.com/hud-fha-suspend-forec...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6570</th>\n",
       "      <td>2020-02-17-085956</td>\n",
       "      <td>whoever is the interested player,</td>\n",
       "      <td>Hardeep Singh Puri</td>\n",
       "      <td>[Q5655835]</td>\n",
       "      <td>2020-02-17 10:15:26</td>\n",
       "      <td>6</td>\n",
       "      <td>[[Hardeep Singh Puri, 0.9405], [None, 0.0595]]</td>\n",
       "      <td>[https://www.livemint.com/news/india/-air-indi...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>2020-03-02-078576</td>\n",
       "      <td>Why now, 2021? Here's why,</td>\n",
       "      <td>Michael J. Graham</td>\n",
       "      <td>[Q6831418]</td>\n",
       "      <td>2020-03-02 21:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Michael J. Graham, 0.6261], [None, 0.3739]]</td>\n",
       "      <td>[https://thecourier.com/ohio-news/2020/03/02/p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>2020-04-14-074488</td>\n",
       "      <td>Why should a running back be treated less than...</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>[Q452154]</td>\n",
       "      <td>2020-04-14 22:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Mark Ingram, 0.5275], [None, 0.4657], [Chris...</td>\n",
       "      <td>[http://registercitizen.com/sports/article/Ing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>2020-04-15-078413</td>\n",
       "      <td>Why would I leave here where I'm healthy, to t...</td>\n",
       "      <td>Pauline Pearce</td>\n",
       "      <td>[Q55076551]</td>\n",
       "      <td>2020-04-15 10:10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pauline Pearce, 0.8222], [None, 0.1778]]</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-england-london-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>2020-03-26-086246</td>\n",
       "      <td>will not be the first commissioner of an Ameri...</td>\n",
       "      <td>Adam Silver</td>\n",
       "      <td>[Q4679786]</td>\n",
       "      <td>2020-03-26 22:20:01</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Adam Silver, 0.5877], [None, 0.3937], [Jay M...</td>\n",
       "      <td>[http://sportsbusinessdaily.com/Daily/Issues/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6575 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1     2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "2     2020-01-17-000357  [ The delay ] will have an impact [ on Slough ...   \n",
       "3     2020-04-02-000239  [ The scheme ] treats addiction as an illness ...   \n",
       "4     2020-03-19-000276  [ These ] actions will allow households who ha...   \n",
       "...                 ...                                                ...   \n",
       "6570  2020-02-17-085956                  whoever is the interested player,   \n",
       "6571  2020-03-02-078576                         Why now, 2021? Here's why,   \n",
       "6572  2020-04-14-074488  Why should a running back be treated less than...   \n",
       "6573  2020-04-15-078413  Why would I leave here where I'm healthy, to t...   \n",
       "6574  2020-03-26-086246  will not be the first commissioner of an Ameri...   \n",
       "\n",
       "                  speaker         qids                date  numOccurrences  \\\n",
       "0              Sue Myrick    [Q367796] 2020-01-16 12:00:13               1   \n",
       "1     Meghan King Edmonds  [Q20684375] 2020-01-24 20:37:09               4   \n",
       "2            Dexter Smith   [Q5268447] 2020-01-17 13:03:00               1   \n",
       "3         Barry Coppinger   [Q4864119] 2020-04-02 14:18:20               1   \n",
       "4              Ben Carson    [Q816459] 2020-03-19 19:14:00               1   \n",
       "...                   ...          ...                 ...             ...   \n",
       "6570   Hardeep Singh Puri   [Q5655835] 2020-02-17 10:15:26               6   \n",
       "6571    Michael J. Graham   [Q6831418] 2020-03-02 21:03:20               1   \n",
       "6572          Mark Ingram    [Q452154] 2020-04-14 22:03:37               1   \n",
       "6573       Pauline Pearce  [Q55076551] 2020-04-15 10:10:33               1   \n",
       "6574          Adam Silver   [Q4679786] 2020-03-26 22:20:01               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...   \n",
       "1     [[Meghan King Edmonds, 0.5446], [None, 0.2705]...   \n",
       "2                [[Dexter Smith, 0.924], [None, 0.076]]   \n",
       "3           [[Barry Coppinger, 0.9017], [None, 0.0983]]   \n",
       "4                [[Ben Carson, 0.9227], [None, 0.0773]]   \n",
       "...                                                 ...   \n",
       "6570     [[Hardeep Singh Puri, 0.9405], [None, 0.0595]]   \n",
       "6571      [[Michael J. Graham, 0.6261], [None, 0.3739]]   \n",
       "6572  [[Mark Ingram, 0.5275], [None, 0.4657], [Chris...   \n",
       "6573         [[Pauline Pearce, 0.8222], [None, 0.1778]]   \n",
       "6574  [[Adam Silver, 0.5877], [None, 0.3937], [Jay M...   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://thehill.com/opinion/international/4782...     E  \n",
       "1     [https://people.com/parents/meghan-king-edmond...     E  \n",
       "2     [http://www.sloughexpress.co.uk/gallery/slough...     E  \n",
       "3     [http://www.theweek.co.uk/106479/why-police-ar...     E  \n",
       "4     [https://mortgageorb.com/hud-fha-suspend-forec...     E  \n",
       "...                                                 ...   ...  \n",
       "6570  [https://www.livemint.com/news/india/-air-indi...     E  \n",
       "6571  [https://thecourier.com/ohio-news/2020/03/02/p...     E  \n",
       "6572  [http://registercitizen.com/sports/article/Ing...     E  \n",
       "6573  [https://www.bbc.co.uk/news/uk-england-london-...     E  \n",
       "6574  [http://sportsbusinessdaily.com/Daily/Issues/2...     E  \n",
       "\n",
       "[6575 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-record",
   "metadata": {},
   "source": [
    "#### Applying to a portion of the dataframe (to compare with the cell above)\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "separate-better",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
       "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
       "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[ The delay ] will have an impact [ on Slough ...</td>\n",
       "      <td>Dexter Smith</td>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>2020-01-17 13:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dexter Smith, 0.924], [None, 0.076]]</td>\n",
       "      <td>[http://www.sloughexpress.co.uk/gallery/slough...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[ The scheme ] treats addiction as an illness ...</td>\n",
       "      <td>Barry Coppinger</td>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>2020-04-02 14:18:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Barry Coppinger, 0.9017], [None, 0.0983]]</td>\n",
       "      <td>[http://www.theweek.co.uk/106479/why-police-ar...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[ These ] actions will allow households who ha...</td>\n",
       "      <td>Ben Carson</td>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>2020-03-19 19:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Ben Carson, 0.9227], [None, 0.0773]]</td>\n",
       "      <td>[https://mortgageorb.com/hud-fha-suspend-forec...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6570</th>\n",
       "      <td>2020-02-17-085956</td>\n",
       "      <td>whoever is the interested player,</td>\n",
       "      <td>Hardeep Singh Puri</td>\n",
       "      <td>[Q5655835]</td>\n",
       "      <td>2020-02-17 10:15:26</td>\n",
       "      <td>6</td>\n",
       "      <td>[[Hardeep Singh Puri, 0.9405], [None, 0.0595]]</td>\n",
       "      <td>[https://www.livemint.com/news/india/-air-indi...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>2020-03-02-078576</td>\n",
       "      <td>Why now, 2021? Here's why,</td>\n",
       "      <td>Michael J. Graham</td>\n",
       "      <td>[Q6831418]</td>\n",
       "      <td>2020-03-02 21:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Michael J. Graham, 0.6261], [None, 0.3739]]</td>\n",
       "      <td>[https://thecourier.com/ohio-news/2020/03/02/p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>2020-04-14-074488</td>\n",
       "      <td>Why should a running back be treated less than...</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>[Q452154]</td>\n",
       "      <td>2020-04-14 22:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Mark Ingram, 0.5275], [None, 0.4657], [Chris...</td>\n",
       "      <td>[http://registercitizen.com/sports/article/Ing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>2020-04-15-078413</td>\n",
       "      <td>Why would I leave here where I'm healthy, to t...</td>\n",
       "      <td>Pauline Pearce</td>\n",
       "      <td>[Q55076551]</td>\n",
       "      <td>2020-04-15 10:10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pauline Pearce, 0.8222], [None, 0.1778]]</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-england-london-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>2020-03-26-086246</td>\n",
       "      <td>will not be the first commissioner of an Ameri...</td>\n",
       "      <td>Adam Silver</td>\n",
       "      <td>[Q4679786]</td>\n",
       "      <td>2020-03-26 22:20:01</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Adam Silver, 0.5877], [None, 0.3937], [Jay M...</td>\n",
       "      <td>[http://sportsbusinessdaily.com/Daily/Issues/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6575 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1     2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "2     2020-01-17-000357  [ The delay ] will have an impact [ on Slough ...   \n",
       "3     2020-04-02-000239  [ The scheme ] treats addiction as an illness ...   \n",
       "4     2020-03-19-000276  [ These ] actions will allow households who ha...   \n",
       "...                 ...                                                ...   \n",
       "6570  2020-02-17-085956                  whoever is the interested player,   \n",
       "6571  2020-03-02-078576                         Why now, 2021? Here's why,   \n",
       "6572  2020-04-14-074488  Why should a running back be treated less than...   \n",
       "6573  2020-04-15-078413  Why would I leave here where I'm healthy, to t...   \n",
       "6574  2020-03-26-086246  will not be the first commissioner of an Ameri...   \n",
       "\n",
       "                  speaker         qids                date  numOccurrences  \\\n",
       "0              Sue Myrick    [Q367796] 2020-01-16 12:00:13               1   \n",
       "1     Meghan King Edmonds  [Q20684375] 2020-01-24 20:37:09               4   \n",
       "2            Dexter Smith   [Q5268447] 2020-01-17 13:03:00               1   \n",
       "3         Barry Coppinger   [Q4864119] 2020-04-02 14:18:20               1   \n",
       "4              Ben Carson    [Q816459] 2020-03-19 19:14:00               1   \n",
       "...                   ...          ...                 ...             ...   \n",
       "6570   Hardeep Singh Puri   [Q5655835] 2020-02-17 10:15:26               6   \n",
       "6571    Michael J. Graham   [Q6831418] 2020-03-02 21:03:20               1   \n",
       "6572          Mark Ingram    [Q452154] 2020-04-14 22:03:37               1   \n",
       "6573       Pauline Pearce  [Q55076551] 2020-04-15 10:10:33               1   \n",
       "6574          Adam Silver   [Q4679786] 2020-03-26 22:20:01               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...   \n",
       "1     [[Meghan King Edmonds, 0.5446], [None, 0.2705]...   \n",
       "2                [[Dexter Smith, 0.924], [None, 0.076]]   \n",
       "3           [[Barry Coppinger, 0.9017], [None, 0.0983]]   \n",
       "4                [[Ben Carson, 0.9227], [None, 0.0773]]   \n",
       "...                                                 ...   \n",
       "6570     [[Hardeep Singh Puri, 0.9405], [None, 0.0595]]   \n",
       "6571      [[Michael J. Graham, 0.6261], [None, 0.3739]]   \n",
       "6572  [[Mark Ingram, 0.5275], [None, 0.4657], [Chris...   \n",
       "6573         [[Pauline Pearce, 0.8222], [None, 0.1778]]   \n",
       "6574  [[Adam Silver, 0.5877], [None, 0.3937], [Jay M...   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://thehill.com/opinion/international/4782...     E  \n",
       "1     [https://people.com/parents/meghan-king-edmond...     E  \n",
       "2     [http://www.sloughexpress.co.uk/gallery/slough...     E  \n",
       "3     [http://www.theweek.co.uk/106479/why-police-ar...     E  \n",
       "4     [https://mortgageorb.com/hud-fha-suspend-forec...     E  \n",
       "...                                                 ...   ...  \n",
       "6570  [https://www.livemint.com/news/india/-air-indi...     E  \n",
       "6571  [https://thecourier.com/ohio-news/2020/03/02/p...     E  \n",
       "6572  [http://registercitizen.com/sports/article/Ing...     E  \n",
       "6573  [https://www.bbc.co.uk/news/uk-england-london-...     E  \n",
       "6574  [http://sportsbusinessdaily.com/Daily/Issues/2...     E  \n",
       "\n",
       "[6575 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speaker = df.drop(df[df['speaker']=='None'].index)\n",
    "df_speaker = df_speaker.reset_index(drop=True)\n",
    "df_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "demographic-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 0 rows had no speaker and were thus removed\n"
     ]
    }
   ],
   "source": [
    "print('In total,', len(df)-len(df_speaker), 'rows had no speaker and were thus removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-midwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floppy-amino",
   "metadata": {},
   "source": [
    "### Remove speakers for which the probability is smaller than a threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-institute",
   "metadata": {},
   "source": [
    "#### Automated fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "turkish-magnet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 9525 rows\n",
      "\n",
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 9540 rows\n",
      "\n",
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 9500 rows\n",
      "\n",
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 9506 rows\n",
      "\n",
      "Processing chunk with 10000 rows\n",
      "Length of the chunk is now 9528 rows\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f98031c14444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bz2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdropped_prob_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_chunk_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mlines_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;31m# Make sure that the returned objects have the right index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m             )\n\u001b[1;32m   1081\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_chunk_probas(chunk):\n",
    "    print(f'Processing chunk with {len(chunk)} rows')\n",
    "    #Define threshold (50%)\n",
    "    threshold_probas = 0.5\n",
    "    \n",
    "    #Gather the first probability for each row\n",
    "    string_probas, nber_probas = [], []\n",
    "    string_probas = [chunk['probas'][i][0][1] for i in chunk.index]\n",
    "    nber_probas = list(map(float, string_probas))\n",
    "    series_probas = pd.Series(nber_probas, dtype='float64', index=chunk.index)\n",
    "    \n",
    "    #Check if the probability is larger than the threshold, if not remove corresponding index\n",
    "    chunk = chunk.drop(series_probas[series_probas < threshold_probas].index)\n",
    "    chunk = chunk.reset_index(drop=True)\n",
    "    \n",
    "    print('Length of the chunk is now', len(chunk), 'rows\\n')\n",
    "    return chunk\n",
    "\n",
    "with pd.read_json(FILE2016, lines=True, compression='bz2', chunksize=10000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        dropped_prob_chunk = process_chunk_probas(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-transsexual",
   "metadata": {},
   "source": [
    "##### Test over the downloaded datafame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "referenced-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 6575 rows\n",
      "Length of the chunk is now 6282 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
       "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
       "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[ The delay ] will have an impact [ on Slough ...</td>\n",
       "      <td>Dexter Smith</td>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>2020-01-17 13:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dexter Smith, 0.924], [None, 0.076]]</td>\n",
       "      <td>[http://www.sloughexpress.co.uk/gallery/slough...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[ The scheme ] treats addiction as an illness ...</td>\n",
       "      <td>Barry Coppinger</td>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>2020-04-02 14:18:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Barry Coppinger, 0.9017], [None, 0.0983]]</td>\n",
       "      <td>[http://www.theweek.co.uk/106479/why-police-ar...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[ These ] actions will allow households who ha...</td>\n",
       "      <td>Ben Carson</td>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>2020-03-19 19:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Ben Carson, 0.9227], [None, 0.0773]]</td>\n",
       "      <td>[https://mortgageorb.com/hud-fha-suspend-forec...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>2020-02-17-085956</td>\n",
       "      <td>whoever is the interested player,</td>\n",
       "      <td>Hardeep Singh Puri</td>\n",
       "      <td>[Q5655835]</td>\n",
       "      <td>2020-02-17 10:15:26</td>\n",
       "      <td>6</td>\n",
       "      <td>[[Hardeep Singh Puri, 0.9405], [None, 0.0595]]</td>\n",
       "      <td>[https://www.livemint.com/news/india/-air-indi...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>2020-03-02-078576</td>\n",
       "      <td>Why now, 2021? Here's why,</td>\n",
       "      <td>Michael J. Graham</td>\n",
       "      <td>[Q6831418]</td>\n",
       "      <td>2020-03-02 21:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Michael J. Graham, 0.6261], [None, 0.3739]]</td>\n",
       "      <td>[https://thecourier.com/ohio-news/2020/03/02/p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>2020-04-14-074488</td>\n",
       "      <td>Why should a running back be treated less than...</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>[Q452154]</td>\n",
       "      <td>2020-04-14 22:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Mark Ingram, 0.5275], [None, 0.4657], [Chris...</td>\n",
       "      <td>[http://registercitizen.com/sports/article/Ing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>2020-04-15-078413</td>\n",
       "      <td>Why would I leave here where I'm healthy, to t...</td>\n",
       "      <td>Pauline Pearce</td>\n",
       "      <td>[Q55076551]</td>\n",
       "      <td>2020-04-15 10:10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pauline Pearce, 0.8222], [None, 0.1778]]</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-england-london-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>2020-03-26-086246</td>\n",
       "      <td>will not be the first commissioner of an Ameri...</td>\n",
       "      <td>Adam Silver</td>\n",
       "      <td>[Q4679786]</td>\n",
       "      <td>2020-03-26 22:20:01</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Adam Silver, 0.5877], [None, 0.3937], [Jay M...</td>\n",
       "      <td>[http://sportsbusinessdaily.com/Daily/Issues/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6282 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1     2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "2     2020-01-17-000357  [ The delay ] will have an impact [ on Slough ...   \n",
       "3     2020-04-02-000239  [ The scheme ] treats addiction as an illness ...   \n",
       "4     2020-03-19-000276  [ These ] actions will allow households who ha...   \n",
       "...                 ...                                                ...   \n",
       "6277  2020-02-17-085956                  whoever is the interested player,   \n",
       "6278  2020-03-02-078576                         Why now, 2021? Here's why,   \n",
       "6279  2020-04-14-074488  Why should a running back be treated less than...   \n",
       "6280  2020-04-15-078413  Why would I leave here where I'm healthy, to t...   \n",
       "6281  2020-03-26-086246  will not be the first commissioner of an Ameri...   \n",
       "\n",
       "                  speaker         qids                date  numOccurrences  \\\n",
       "0              Sue Myrick    [Q367796] 2020-01-16 12:00:13               1   \n",
       "1     Meghan King Edmonds  [Q20684375] 2020-01-24 20:37:09               4   \n",
       "2            Dexter Smith   [Q5268447] 2020-01-17 13:03:00               1   \n",
       "3         Barry Coppinger   [Q4864119] 2020-04-02 14:18:20               1   \n",
       "4              Ben Carson    [Q816459] 2020-03-19 19:14:00               1   \n",
       "...                   ...          ...                 ...             ...   \n",
       "6277   Hardeep Singh Puri   [Q5655835] 2020-02-17 10:15:26               6   \n",
       "6278    Michael J. Graham   [Q6831418] 2020-03-02 21:03:20               1   \n",
       "6279          Mark Ingram    [Q452154] 2020-04-14 22:03:37               1   \n",
       "6280       Pauline Pearce  [Q55076551] 2020-04-15 10:10:33               1   \n",
       "6281          Adam Silver   [Q4679786] 2020-03-26 22:20:01               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...   \n",
       "1     [[Meghan King Edmonds, 0.5446], [None, 0.2705]...   \n",
       "2                [[Dexter Smith, 0.924], [None, 0.076]]   \n",
       "3           [[Barry Coppinger, 0.9017], [None, 0.0983]]   \n",
       "4                [[Ben Carson, 0.9227], [None, 0.0773]]   \n",
       "...                                                 ...   \n",
       "6277     [[Hardeep Singh Puri, 0.9405], [None, 0.0595]]   \n",
       "6278      [[Michael J. Graham, 0.6261], [None, 0.3739]]   \n",
       "6279  [[Mark Ingram, 0.5275], [None, 0.4657], [Chris...   \n",
       "6280         [[Pauline Pearce, 0.8222], [None, 0.1778]]   \n",
       "6281  [[Adam Silver, 0.5877], [None, 0.3937], [Jay M...   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://thehill.com/opinion/international/4782...     E  \n",
       "1     [https://people.com/parents/meghan-king-edmond...     E  \n",
       "2     [http://www.sloughexpress.co.uk/gallery/slough...     E  \n",
       "3     [http://www.theweek.co.uk/106479/why-police-ar...     E  \n",
       "4     [https://mortgageorb.com/hud-fha-suspend-forec...     E  \n",
       "...                                                 ...   ...  \n",
       "6277  [https://www.livemint.com/news/india/-air-indi...     E  \n",
       "6278  [https://thecourier.com/ohio-news/2020/03/02/p...     E  \n",
       "6279  [http://registercitizen.com/sports/article/Ing...     E  \n",
       "6280  [https://www.bbc.co.uk/news/uk-england-london-...     E  \n",
       "6281  [http://sportsbusinessdaily.com/Daily/Issues/2...     E  \n",
       "\n",
       "[6282 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_chunk_probas(df)\n",
    "df\n",
    "#once again, seems not to work...\n",
    "# This is because you were not returning anything; so now the process_chunj_probas \n",
    "# actually returns the updated df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-sperm",
   "metadata": {},
   "source": [
    "#### Applying to a portion of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "lesser-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
       "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>Meghan King Edmonds</td>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
       "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[ The delay ] will have an impact [ on Slough ...</td>\n",
       "      <td>Dexter Smith</td>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>2020-01-17 13:03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Dexter Smith, 0.924], [None, 0.076]]</td>\n",
       "      <td>[http://www.sloughexpress.co.uk/gallery/slough...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[ The scheme ] treats addiction as an illness ...</td>\n",
       "      <td>Barry Coppinger</td>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>2020-04-02 14:18:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Barry Coppinger, 0.9017], [None, 0.0983]]</td>\n",
       "      <td>[http://www.theweek.co.uk/106479/why-police-ar...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[ These ] actions will allow households who ha...</td>\n",
       "      <td>Ben Carson</td>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>2020-03-19 19:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Ben Carson, 0.9227], [None, 0.0773]]</td>\n",
       "      <td>[https://mortgageorb.com/hud-fha-suspend-forec...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>2020-02-17-085956</td>\n",
       "      <td>whoever is the interested player,</td>\n",
       "      <td>Hardeep Singh Puri</td>\n",
       "      <td>[Q5655835]</td>\n",
       "      <td>2020-02-17 10:15:26</td>\n",
       "      <td>6</td>\n",
       "      <td>[[Hardeep Singh Puri, 0.9405], [None, 0.0595]]</td>\n",
       "      <td>[https://www.livemint.com/news/india/-air-indi...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>2020-03-02-078576</td>\n",
       "      <td>Why now, 2021? Here's why,</td>\n",
       "      <td>Michael J. Graham</td>\n",
       "      <td>[Q6831418]</td>\n",
       "      <td>2020-03-02 21:03:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Michael J. Graham, 0.6261], [None, 0.3739]]</td>\n",
       "      <td>[https://thecourier.com/ohio-news/2020/03/02/p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>2020-04-14-074488</td>\n",
       "      <td>Why should a running back be treated less than...</td>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>[Q452154]</td>\n",
       "      <td>2020-04-14 22:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Mark Ingram, 0.5275], [None, 0.4657], [Chris...</td>\n",
       "      <td>[http://registercitizen.com/sports/article/Ing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>2020-04-15-078413</td>\n",
       "      <td>Why would I leave here where I'm healthy, to t...</td>\n",
       "      <td>Pauline Pearce</td>\n",
       "      <td>[Q55076551]</td>\n",
       "      <td>2020-04-15 10:10:33</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Pauline Pearce, 0.8222], [None, 0.1778]]</td>\n",
       "      <td>[https://www.bbc.co.uk/news/uk-england-london-...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>2020-03-26-086246</td>\n",
       "      <td>will not be the first commissioner of an Ameri...</td>\n",
       "      <td>Adam Silver</td>\n",
       "      <td>[Q4679786]</td>\n",
       "      <td>2020-03-26 22:20:01</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Adam Silver, 0.5877], [None, 0.3937], [Jay M...</td>\n",
       "      <td>[http://sportsbusinessdaily.com/Daily/Issues/2...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6282 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "0     2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "1     2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "2     2020-01-17-000357  [ The delay ] will have an impact [ on Slough ...   \n",
       "3     2020-04-02-000239  [ The scheme ] treats addiction as an illness ...   \n",
       "4     2020-03-19-000276  [ These ] actions will allow households who ha...   \n",
       "...                 ...                                                ...   \n",
       "6277  2020-02-17-085956                  whoever is the interested player,   \n",
       "6278  2020-03-02-078576                         Why now, 2021? Here's why,   \n",
       "6279  2020-04-14-074488  Why should a running back be treated less than...   \n",
       "6280  2020-04-15-078413  Why would I leave here where I'm healthy, to t...   \n",
       "6281  2020-03-26-086246  will not be the first commissioner of an Ameri...   \n",
       "\n",
       "                  speaker         qids                date  numOccurrences  \\\n",
       "0              Sue Myrick    [Q367796] 2020-01-16 12:00:13               1   \n",
       "1     Meghan King Edmonds  [Q20684375] 2020-01-24 20:37:09               4   \n",
       "2            Dexter Smith   [Q5268447] 2020-01-17 13:03:00               1   \n",
       "3         Barry Coppinger   [Q4864119] 2020-04-02 14:18:20               1   \n",
       "4              Ben Carson    [Q816459] 2020-03-19 19:14:00               1   \n",
       "...                   ...          ...                 ...             ...   \n",
       "6277   Hardeep Singh Puri   [Q5655835] 2020-02-17 10:15:26               6   \n",
       "6278    Michael J. Graham   [Q6831418] 2020-03-02 21:03:20               1   \n",
       "6279          Mark Ingram    [Q452154] 2020-04-14 22:03:37               1   \n",
       "6280       Pauline Pearce  [Q55076551] 2020-04-15 10:10:33               1   \n",
       "6281          Adam Silver   [Q4679786] 2020-03-26 22:20:01               1   \n",
       "\n",
       "                                                 probas  \\\n",
       "0     [[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...   \n",
       "1     [[Meghan King Edmonds, 0.5446], [None, 0.2705]...   \n",
       "2                [[Dexter Smith, 0.924], [None, 0.076]]   \n",
       "3           [[Barry Coppinger, 0.9017], [None, 0.0983]]   \n",
       "4                [[Ben Carson, 0.9227], [None, 0.0773]]   \n",
       "...                                                 ...   \n",
       "6277     [[Hardeep Singh Puri, 0.9405], [None, 0.0595]]   \n",
       "6278      [[Michael J. Graham, 0.6261], [None, 0.3739]]   \n",
       "6279  [[Mark Ingram, 0.5275], [None, 0.4657], [Chris...   \n",
       "6280         [[Pauline Pearce, 0.8222], [None, 0.1778]]   \n",
       "6281  [[Adam Silver, 0.5877], [None, 0.3937], [Jay M...   \n",
       "\n",
       "                                                   urls phase  \n",
       "0     [http://thehill.com/opinion/international/4782...     E  \n",
       "1     [https://people.com/parents/meghan-king-edmond...     E  \n",
       "2     [http://www.sloughexpress.co.uk/gallery/slough...     E  \n",
       "3     [http://www.theweek.co.uk/106479/why-police-ar...     E  \n",
       "4     [https://mortgageorb.com/hud-fha-suspend-forec...     E  \n",
       "...                                                 ...   ...  \n",
       "6277  [https://www.livemint.com/news/india/-air-indi...     E  \n",
       "6278  [https://thecourier.com/ohio-news/2020/03/02/p...     E  \n",
       "6279  [http://registercitizen.com/sports/article/Ing...     E  \n",
       "6280  [https://www.bbc.co.uk/news/uk-england-london-...     E  \n",
       "6281  [http://sportsbusinessdaily.com/Daily/Issues/2...     E  \n",
       "\n",
       "[6282 rows x 9 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define threshold (50%)\n",
    "threshold_probas = 0.5\n",
    "\n",
    "#Gather the first probability for each row\n",
    "string_probas = [df['probas'][i][0][1] for i in range(len(df))]\n",
    "nber_probas = list(map(float, string_probas))\n",
    "series_probas = pd.Series(nber_probas)\n",
    "\n",
    "#Check if the probability is larger than the threshold, if not remove the row\n",
    "df_probas = df.drop(series_probas[series_probas < threshold_probas].index)\n",
    "df_probas = df_probas.reset_index(drop=True)\n",
    "df_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "liked-nomination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 0 speakers had a probality smaller than 0.5 and were thus removed\n"
     ]
    }
   ],
   "source": [
    "print('In total,', len(df)-len(df_probas), 'speakers had a probality smaller than', threshold_probas, 'and were thus removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-practitioner",
   "metadata": {},
   "source": [
    "#### Think to other scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If all speakers are women but with proba < threshold, keep the row ?\n",
    "#might cause some problem for interpretation (country of origin of the speaker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-flavor",
   "metadata": {},
   "source": [
    "#### Additional notes Lavi 1.11.\n",
    "\n",
    "- I don't think we should keep the speakers if proba < threshold, because like you state above, this will create additional problems\n",
    "\n",
    "Possible additional cleaning may include:\n",
    "- checking nan values \n",
    "- verify absurd QuoteID or QID \n",
    "- make sure quotes are non empty\n",
    "\n",
    "#### Additional notes SÃ©lÃ¨ne 1.11.\n",
    "I saw in 2019 a quote that looks wrong (\"% 9: D: D @? 6 H2J H6 E9@F89E H6 4@F=5 8: G6 3...\"). Idk if possible but we could perhaps remove quotes with only weird symbols as part of cleaning?\n",
    "\n",
    "--> This was a None speaker but indeed would be good, some function for sure exist already made :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-thanks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
