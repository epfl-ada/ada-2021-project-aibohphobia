{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import bz2\n",
    "import json\n",
    "from tld import get_tld\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import string\n",
    "import math\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "nltk.download()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_clean_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c481f17",
   "metadata": {},
   "source": [
    "### CREATE PATHS: change according to local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "FILE2019 = DATA_PATH + 'quotes-2019.json.bz2'\n",
    "PATH_OUT = DATA_PATH + 'clean-quotes-2019.json.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e7b2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_base = pd.read_json(FILE2019, lines=True, compression='bz2', nrows=1000)\n",
    "df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284fa36",
   "metadata": {},
   "source": [
    "## Create a dictionnary of categories and associated synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13416c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchers = {\"art\": [\"art\", \"paint\", \"draw\", \"museum\"], \\\n",
    "            \"business\": [\"business\", \"finance\", \"economy\", \"commerce\", \"bank\", \"money\", \"trade\"], \\\n",
    "            \"entertainment\":[\"entertainment\"], \n",
    "            \"fashion\":[\"fashion\", \"couture\", \"designer\"], \\\n",
    "            \"medicine\":[\"medicine\", \"health\", \"pharmacy\", \"wellbeing\", \"body\"], \\\n",
    "            \"music\":[\"music\", \"song\", \"album\", \"concert\"], \\\n",
    "            \"politics\":[\"politics\", \"government\"], \\\n",
    "            \"science\":[\"science\", \"research\"], \\\n",
    "            \"sport\": [\"sport\", \"football\", \"athletics\", \"swimming\", \"rugby\", \"tennis\", \"volleyball\", \"ski\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f40023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this as doesn't return good list\n",
    "\n",
    "'''\n",
    "\n",
    "def find_synonyms(matchers):\n",
    "    for category in matchers:\n",
    "        synonyms = []\n",
    "        for i in range(len(matchers[category])):\n",
    "            word = matchers[category][i]\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    synonyms.append(l.name())\n",
    "            matchers[category] = synonyms\n",
    "    return matchers\n",
    "\n",
    "matchers = find_synonyms(matchers)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69092e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalizeDictionary(matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59938ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb5ade",
   "metadata": {},
   "source": [
    "### PROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1cda8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pickle the chunks of dataframe for later\n",
    "n_chunks = 0\n",
    "\n",
    "with pd.read_json(FILE2019, lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    for chunk in df_reader:\n",
    "        n_chunks += 1\n",
    "        chunk_cleaned, chunk_length = process_chunk_complete(chunk, 0.5, matchers)\n",
    "        with open(PATH_OUT, 'ab') as d_file:\n",
    "            pickle.dump(chunk_cleaned, d_file)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pickled file\n",
    "for chunk_nbr in range(n_chunks):\n",
    "    with open(PATH_OUT, 'rb') as d_file:\n",
    "        chunk = pickle.load(d_file)\n",
    "        # Need to load m times if you want to get to the m^th file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b5e9a",
   "metadata": {},
   "source": [
    "### Without pickle / writing to new json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.read_json(FILE2019, lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    with bz2.open(PATH_OUT, 'wb') as d_file:\n",
    "        for chunk in df_reader:\n",
    "            chunk_cleaned, chunk_length = process_chunk_complete(chunk, 0.5, matchers)\n",
    "            chunk_json = chunk_cleaned.to_json(orient='columns')#, index=False) #write it to pickle file instead\n",
    "            d_file.write((chunk_json+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fce151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(DATA_PATH + 'clean-quotes-2019.json.bz2', orient='columns', compression='bz2')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(DATA_PATH + 'clean-quotes-2019.json.bz2', orient='columns', compression='bz2', lines=True, nrows=100)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cebd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.read_json(DATA_PATH + 'clean-quotes-2019.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
