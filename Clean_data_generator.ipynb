{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12ef860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/selene/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/selene/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import bz2\n",
    "import json\n",
    "from tld import get_tld\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import string\n",
    "import math\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "nltk.download()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "854b391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/selene/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/selene/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Data_clean_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003d69a",
   "metadata": {},
   "source": [
    "### CREATE PATHS: change according to local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40cb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "FILE2019 = DATA_PATH + 'quotes-2019.json.bz2'\n",
    "PATH_OUT = DATA_PATH + 'clean-quotes-2019.json.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe79fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-14-000009</td>\n",
       "      <td>% 9: D: D @? 6 H2J H6 E9@F89E H6 4@F=5 8: G6 3...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14 07:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.5595], [Julio Morales, 0.4405]]</td>\n",
       "      <td>[http://www.ivpressonline.com/news/local/ivc-f...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-08-048753</td>\n",
       "      <td>It is immoral. It is harmful. It is hurtful.</td>\n",
       "      <td>President Donald Trump</td>\n",
       "      <td>[Q22686]</td>\n",
       "      <td>2019-04-08 16:22:00</td>\n",
       "      <td>44</td>\n",
       "      <td>[[President Donald Trump, 0.5802], [None, 0.36...</td>\n",
       "      <td>[https://www.mercedsunstar.com/news/business/a...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-17-000030</td>\n",
       "      <td>[ Amber ] loves her son more than anything,</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-07-17 22:54:35</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.8276], [Amber Portwood, 0.1724]]</td>\n",
       "      <td>[https://www.inquisitr.com/5535969/did-amber-p...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-15-053302</td>\n",
       "      <td>It is important for our equine science student...</td>\n",
       "      <td>Sally Johnson</td>\n",
       "      <td>[Q42336656]</td>\n",
       "      <td>2019-05-15 18:03:22</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sally Johnson, 0.5721], [None, 0.4279]]</td>\n",
       "      <td>[https://www.lanereport.com/113381/2019/05/qua...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-20-000011</td>\n",
       "      <td>... an Afrikaans family living in South Africa...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-04-20 22:30:57</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.8331], [you long, 0.1669]]</td>\n",
       "      <td>[http://filmthreat.com/reviews/the-harvester/]</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2019-10-22-049545</td>\n",
       "      <td>It is very unstructured, uncourt-like and it i...</td>\n",
       "      <td>Ellen Mirojnick</td>\n",
       "      <td>[Q15919390]</td>\n",
       "      <td>2019-10-22 19:00:04</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Ellen Mirojnick, 0.7907], [None, 0.2093]]</td>\n",
       "      <td>[http://www.blastr.com/syfywire/ellen-mirojnic...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019-09-26-000599</td>\n",
       "      <td>12 Movements from Romeo and Juliet</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-09-26 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>[[None, 0.5111], [Sergei Babayan, 0.2205], [Da...</td>\n",
       "      <td>[http://news.cornell.edu/stories/2019/09/thing...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2019-06-17-046011</td>\n",
       "      <td>It is vital that investigators get access to T...</td>\n",
       "      <td>Danielle Smith</td>\n",
       "      <td>[Q22957142, Q5219439]</td>\n",
       "      <td>2019-06-17 00:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>[[Danielle Smith, 0.5516], [None, 0.4484]]</td>\n",
       "      <td>[http://www.hitz939.com.au/news/national-news/...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-05-30-000684</td>\n",
       "      <td>20 new songs that will change your lives.</td>\n",
       "      <td>Liam Gallagher</td>\n",
       "      <td>[Q216708, Q30084404]</td>\n",
       "      <td>2019-05-30 11:27:45</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Liam Gallagher, 0.8319], [None, 0.1503], [Gr...</td>\n",
       "      <td>[https://www.nme.com/news/music/liam-gallagher...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-01-23-054916</td>\n",
       "      <td>It is vital that PSE provides children with th...</td>\n",
       "      <td>John Swinney</td>\n",
       "      <td>[Q333811]</td>\n",
       "      <td>2019-01-23 04:53:48</td>\n",
       "      <td>5</td>\n",
       "      <td>[[John Swinney, 0.8285], [None, 0.165], [Ross ...</td>\n",
       "      <td>[https://www.belfasttelegraph.co.uk/news/uk/ed...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              quoteID                                          quotation  \\\n",
       "0   2019-10-14-000009  % 9: D: D @? 6 H2J H6 E9@F89E H6 4@F=5 8: G6 3...   \n",
       "1   2019-04-08-048753       It is immoral. It is harmful. It is hurtful.   \n",
       "2   2019-07-17-000030        [ Amber ] loves her son more than anything,   \n",
       "3   2019-05-15-053302  It is important for our equine science student...   \n",
       "4   2019-04-20-000011  ... an Afrikaans family living in South Africa...   \n",
       "..                ...                                                ...   \n",
       "95  2019-10-22-049545  It is very unstructured, uncourt-like and it i...   \n",
       "96  2019-09-26-000599                 12 Movements from Romeo and Juliet   \n",
       "97  2019-06-17-046011  It is vital that investigators get access to T...   \n",
       "98  2019-05-30-000684          20 new songs that will change your lives.   \n",
       "99  2019-01-23-054916  It is vital that PSE provides children with th...   \n",
       "\n",
       "                   speaker                   qids                date  \\\n",
       "0                     None                     [] 2019-10-14 07:30:00   \n",
       "1   President Donald Trump               [Q22686] 2019-04-08 16:22:00   \n",
       "2                     None                     [] 2019-07-17 22:54:35   \n",
       "3            Sally Johnson            [Q42336656] 2019-05-15 18:03:22   \n",
       "4                     None                     [] 2019-04-20 22:30:57   \n",
       "..                     ...                    ...                 ...   \n",
       "95         Ellen Mirojnick            [Q15919390] 2019-10-22 19:00:04   \n",
       "96                    None                     [] 2019-09-26 00:00:00   \n",
       "97          Danielle Smith  [Q22957142, Q5219439] 2019-06-17 00:00:00   \n",
       "98          Liam Gallagher   [Q216708, Q30084404] 2019-05-30 11:27:45   \n",
       "99            John Swinney              [Q333811] 2019-01-23 04:53:48   \n",
       "\n",
       "    numOccurrences                                             probas  \\\n",
       "0                1          [[None, 0.5595], [Julio Morales, 0.4405]]   \n",
       "1               44  [[President Donald Trump, 0.5802], [None, 0.36...   \n",
       "2                1         [[None, 0.8276], [Amber Portwood, 0.1724]]   \n",
       "3                1          [[Sally Johnson, 0.5721], [None, 0.4279]]   \n",
       "4                1               [[None, 0.8331], [you long, 0.1669]]   \n",
       "..             ...                                                ...   \n",
       "95               1        [[Ellen Mirojnick, 0.7907], [None, 0.2093]]   \n",
       "96               2  [[None, 0.5111], [Sergei Babayan, 0.2205], [Da...   \n",
       "97              21         [[Danielle Smith, 0.5516], [None, 0.4484]]   \n",
       "98               3  [[Liam Gallagher, 0.8319], [None, 0.1503], [Gr...   \n",
       "99               5  [[John Swinney, 0.8285], [None, 0.165], [Ross ...   \n",
       "\n",
       "                                                 urls phase  \n",
       "0   [http://www.ivpressonline.com/news/local/ivc-f...     E  \n",
       "1   [https://www.mercedsunstar.com/news/business/a...     E  \n",
       "2   [https://www.inquisitr.com/5535969/did-amber-p...     E  \n",
       "3   [https://www.lanereport.com/113381/2019/05/qua...     E  \n",
       "4      [http://filmthreat.com/reviews/the-harvester/]     E  \n",
       "..                                                ...   ...  \n",
       "95  [http://www.blastr.com/syfywire/ellen-mirojnic...     E  \n",
       "96  [http://news.cornell.edu/stories/2019/09/thing...     E  \n",
       "97  [http://www.hitz939.com.au/news/national-news/...     E  \n",
       "98  [https://www.nme.com/news/music/liam-gallagher...     E  \n",
       "99  [https://www.belfasttelegraph.co.uk/news/uk/ed...     E  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = pd.read_json(FILE2019, lines=True, compression='bz2', nrows=100)\n",
    "df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3687579",
   "metadata": {},
   "source": [
    "## Create a dictionnary of categories and associated synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687ce31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchers = {\"art\": [\"art\", \"paint\", \"draw\", \"museum\"], \\\n",
    "            \"business\": [\"business\", \"finance\", \"economy\", \"commerce\", \"bank\", \"money\", \"trade\"], \\\n",
    "            \"entertainment\":[\"entertainment\"], \n",
    "            \"fashion\":[\"fashion\", \"couture\", \"designer\"], \\\n",
    "            \"medicine\":[\"medicine\", \"health\", \"pharmacy\", \"wellbeing\", \"body\"], \\\n",
    "            \"music\":[\"music\", \"song\", \"album\", \"concert\"], \\\n",
    "            \"politics\":[\"politics\", \"government\"], \\\n",
    "            \"science\":[\"science\", \"research\"], \\\n",
    "            \"sport\": [\"sport\", \"football\", \"athletics\", \"swimming\", \"rugby\", \"tennis\", \"volleyball\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this as doesn't return good list\n",
    "\n",
    "'''\n",
    "\n",
    "def find_synonyms(matchers):\n",
    "    for category in matchers:\n",
    "        synonyms = []\n",
    "        for i in range(len(matchers[category])):\n",
    "            word = matchers[category][i]\n",
    "            for syn in wordnet.synsets(word):\n",
    "                for l in syn.lemmas():\n",
    "                    synonyms.append(l.name())\n",
    "            matchers[category] = synonyms\n",
    "    return matchers\n",
    "\n",
    "matchers = find_synonyms(matchers)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a88432",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalizeDictionary(matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5338301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'art': ['art', 'paint', 'draw', 'museum'],\n",
       " 'business': ['busi',\n",
       "  'financ',\n",
       "  'economi',\n",
       "  'commerc',\n",
       "  'bank',\n",
       "  'money',\n",
       "  'trade'],\n",
       " 'entertainment': ['entertain'],\n",
       " 'fashion': ['fashion', 'coutur', 'design'],\n",
       " 'medicine': ['medicin', 'health', 'pharmaci', 'wellb', 'bodi'],\n",
       " 'music': ['music', 'song', 'album', 'concert'],\n",
       " 'politics': ['polit', 'govern'],\n",
       " 'science': ['scienc', 'research'],\n",
       " 'sport': ['sport',\n",
       "  'footbal',\n",
       "  'athlet',\n",
       "  'swim',\n",
       "  'rugbi',\n",
       "  'tenni',\n",
       "  'volleybal']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c065f4",
   "metadata": {},
   "source": [
    "### PROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf187a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 1000 rows\n",
      "Processing chunk with 1000 rows\n",
      "Processing chunk with 1000 rows\n",
      "Processing chunk with 1000 rows\n",
      "Processing chunk with 1000 rows\n",
      "Processing chunk with 1000 rows\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pz/kh7ycnhs1d35h6q5tq_vg4k80000gn/T/ipykernel_5334/1379446452.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mchunk_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_chunk_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatchers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL MA3/Applied Data Analysis/Milestone 2/Data_clean_functions.py\u001b[0m in \u001b[0;36mprocess_chunk_complete\u001b[0;34m(chunk, threshold_proba, matchers)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m#URLS DATA EXTRACTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunk_url_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatchers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mtot_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL MA3/Applied Data Analysis/Milestone 2/Data_clean_functions.py\u001b[0m in \u001b[0;36mChunk_url_extract\u001b[0;34m(chunk, matchers)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mtld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sitename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatchers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0;31m#Append data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mdomains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtld\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL MA3/Applied Data Analysis/Milestone 2/Data_clean_functions.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(matchers, url)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mtag_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgeneral_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetWordsFromURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatchers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatchers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL MA3/Applied Data Analysis/Milestone 2/Data_clean_functions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mtag_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgeneral_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetWordsFromURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatchers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatchers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL MA3/Applied Data Analysis/Milestone 2/Data_clean_functions.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the text without punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Tokenizers divide strings into lists of substrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#stem all words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ada-project/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m/opt/anaconda3/envs/ada-project/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
      "\u001b[0;32m/opt/anaconda3/envs/ada-project/lib/python3.8/site-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ada-project/lib/python3.8/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# With pickle\n",
    "\n",
    "with pd.read_json(FILE2019, lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "        with bz2.open(PATH_OUT, 'wb') as d_file:\n",
    "            for chunk in df_reader:\n",
    "                chunk_cleaned, chunk_length = process_chunk_complete(chunk, 0.5, matchers)\n",
    "                pickle.dump(chunk_cleaned, d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f7ac7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "      <th>sitenames</th>\n",
       "      <th>domain</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-08-048753</td>\n",
       "      <td>It is immoral. It is harmful. It is hurtful.</td>\n",
       "      <td>President Donald Trump</td>\n",
       "      <td>[Q22686]</td>\n",
       "      <td>2019-04-08 16:22:00</td>\n",
       "      <td>44</td>\n",
       "      <td>[[President Donald Trump, 0.5802], [None, 0.36...</td>\n",
       "      <td>[https://www.mercedsunstar.com/news/business/a...</td>\n",
       "      <td>E</td>\n",
       "      <td>[mercedsunstar, sacbee, mynorthwest, lasvegass...</td>\n",
       "      <td>[com, com, com, com, com, com, com, com, com, ...</td>\n",
       "      <td>[[business], [business], [], [], [politics], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-15-053302</td>\n",
       "      <td>It is important for our equine science student...</td>\n",
       "      <td>Sally Johnson</td>\n",
       "      <td>[Q42336656]</td>\n",
       "      <td>2019-05-15 18:03:22</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sally Johnson, 0.5721], [None, 0.4279]]</td>\n",
       "      <td>[https://www.lanereport.com/113381/2019/05/qua...</td>\n",
       "      <td>E</td>\n",
       "      <td>[lanereport]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-27-055406</td>\n",
       "      <td>It is important to many Native American tribes...</td>\n",
       "      <td>Rafael Ortega</td>\n",
       "      <td>[Q16672061, Q3417253, Q3417255, Q48410107]</td>\n",
       "      <td>2019-02-27 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Rafael Ortega, 0.7587], [None, 0.2413]]</td>\n",
       "      <td>[http://kstp.com/news/riverview-corridor-proje...</td>\n",
       "      <td>E</td>\n",
       "      <td>[kstp]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-08-023053</td>\n",
       "      <td>It is impossible, biologically, truly to `rest...</td>\n",
       "      <td>Barry Lopez</td>\n",
       "      <td>[Q809063]</td>\n",
       "      <td>2019-12-08 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Barry Lopez, 0.8142], [None, 0.1858]]</td>\n",
       "      <td>[https://www.timescolonist.com/opinion/op-ed/i...</td>\n",
       "      <td>E</td>\n",
       "      <td>[timescolonist]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-21-000088</td>\n",
       "      <td>[ Chilton ] put it on a little tape recorder a...</td>\n",
       "      <td>Sam the Sham</td>\n",
       "      <td>[Q1971786]</td>\n",
       "      <td>2019-02-21 11:05:34</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Sam the Sham, 0.6472], [None, 0.3278], [Alex...</td>\n",
       "      <td>[http://www.nashvillescene.com/music/features/...</td>\n",
       "      <td>E</td>\n",
       "      <td>[nashvillescene]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[music]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2019-12-28-019903</td>\n",
       "      <td>It's kind of fun to see it. Just to go over th...</td>\n",
       "      <td>Maggie Thompson</td>\n",
       "      <td>[Q733534]</td>\n",
       "      <td>2019-12-28 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Maggie Thompson, 0.7961], [None, 0.2039]]</td>\n",
       "      <td>[http://www.expressnews.com/news/local/article...</td>\n",
       "      <td>E</td>\n",
       "      <td>[expressnews]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2019-04-24-003931</td>\n",
       "      <td>And with a book called Death Threat, I just fe...</td>\n",
       "      <td>Vivek Shraya</td>\n",
       "      <td>[Q7937601]</td>\n",
       "      <td>2019-04-24 20:41:39</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Vivek Shraya, 0.8852], [None, 0.1148]]</td>\n",
       "      <td>[https://www.straight.com/arts/1232356/verses-...</td>\n",
       "      <td>E</td>\n",
       "      <td>[straight]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[art]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>2019-10-21-048385</td>\n",
       "      <td>It's less about what they say to each other an...</td>\n",
       "      <td>Nathan Felix</td>\n",
       "      <td>[Q22277761]</td>\n",
       "      <td>2019-10-21 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Nathan Felix, 0.699], [None, 0.1455], [Domin...</td>\n",
       "      <td>[https://www.tpr.org/post/mcnay-hopes-become-n...</td>\n",
       "      <td>E</td>\n",
       "      <td>[tpr]</td>\n",
       "      <td>[org]</td>\n",
       "      <td>[[art, art]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>2019-02-02-003282</td>\n",
       "      <td>And, you allow the challenge flag to be used o...</td>\n",
       "      <td>Reggie Bush</td>\n",
       "      <td>[Q555271]</td>\n",
       "      <td>2019-02-02 20:07:21</td>\n",
       "      <td>7</td>\n",
       "      <td>[[Reggie Bush, 0.9156], [None, 0.0827], [Cardi...</td>\n",
       "      <td>[http://kron4.com/sports/the-big-game/how-regg...</td>\n",
       "      <td>E</td>\n",
       "      <td>[kron4, krqe, wwlp, everythinglubbock, illinoi...</td>\n",
       "      <td>[com, com, com, com, net, com, com]</td>\n",
       "      <td>[[sport], [sport], [sport], [sport], [sport], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>2019-07-16-048370</td>\n",
       "      <td>It's less than a gallon of gasoline.</td>\n",
       "      <td>John Cooper</td>\n",
       "      <td>[Q1260301, Q1342689, Q16106590, Q16114393, Q18...</td>\n",
       "      <td>2019-07-16 22:24:11</td>\n",
       "      <td>1</td>\n",
       "      <td>[[John Cooper, 0.612], [None, 0.3485], [Jim Ze...</td>\n",
       "      <td>[https://www.al.com/news/mobile/2019/07/90-mon...</td>\n",
       "      <td>E</td>\n",
       "      <td>[al]</td>\n",
       "      <td>[com]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               quoteID                                          quotation  \\\n",
       "0    2019-04-08-048753       It is immoral. It is harmful. It is hurtful.   \n",
       "1    2019-05-15-053302  It is important for our equine science student...   \n",
       "2    2019-02-27-055406  It is important to many Native American tribes...   \n",
       "3    2019-12-08-023053  It is impossible, biologically, truly to `rest...   \n",
       "4    2019-02-21-000088  [ Chilton ] put it on a little tape recorder a...   \n",
       "..                 ...                                                ...   \n",
       "608  2019-12-28-019903  It's kind of fun to see it. Just to go over th...   \n",
       "609  2019-04-24-003931  And with a book called Death Threat, I just fe...   \n",
       "610  2019-10-21-048385  It's less about what they say to each other an...   \n",
       "611  2019-02-02-003282  And, you allow the challenge flag to be used o...   \n",
       "612  2019-07-16-048370               It's less than a gallon of gasoline.   \n",
       "\n",
       "                    speaker  \\\n",
       "0    President Donald Trump   \n",
       "1             Sally Johnson   \n",
       "2             Rafael Ortega   \n",
       "3               Barry Lopez   \n",
       "4              Sam the Sham   \n",
       "..                      ...   \n",
       "608         Maggie Thompson   \n",
       "609            Vivek Shraya   \n",
       "610            Nathan Felix   \n",
       "611             Reggie Bush   \n",
       "612             John Cooper   \n",
       "\n",
       "                                                  qids                date  \\\n",
       "0                                             [Q22686] 2019-04-08 16:22:00   \n",
       "1                                          [Q42336656] 2019-05-15 18:03:22   \n",
       "2           [Q16672061, Q3417253, Q3417255, Q48410107] 2019-02-27 00:00:00   \n",
       "3                                            [Q809063] 2019-12-08 06:00:00   \n",
       "4                                           [Q1971786] 2019-02-21 11:05:34   \n",
       "..                                                 ...                 ...   \n",
       "608                                          [Q733534] 2019-12-28 14:00:00   \n",
       "609                                         [Q7937601] 2019-04-24 20:41:39   \n",
       "610                                        [Q22277761] 2019-10-21 00:00:00   \n",
       "611                                          [Q555271] 2019-02-02 20:07:21   \n",
       "612  [Q1260301, Q1342689, Q16106590, Q16114393, Q18... 2019-07-16 22:24:11   \n",
       "\n",
       "     numOccurrences                                             probas  \\\n",
       "0                44  [[President Donald Trump, 0.5802], [None, 0.36...   \n",
       "1                 1          [[Sally Johnson, 0.5721], [None, 0.4279]]   \n",
       "2                 1          [[Rafael Ortega, 0.7587], [None, 0.2413]]   \n",
       "3                 1            [[Barry Lopez, 0.8142], [None, 0.1858]]   \n",
       "4                 1  [[Sam the Sham, 0.6472], [None, 0.3278], [Alex...   \n",
       "..              ...                                                ...   \n",
       "608               1        [[Maggie Thompson, 0.7961], [None, 0.2039]]   \n",
       "609               1           [[Vivek Shraya, 0.8852], [None, 0.1148]]   \n",
       "610               1  [[Nathan Felix, 0.699], [None, 0.1455], [Domin...   \n",
       "611               7  [[Reggie Bush, 0.9156], [None, 0.0827], [Cardi...   \n",
       "612               1  [[John Cooper, 0.612], [None, 0.3485], [Jim Ze...   \n",
       "\n",
       "                                                  urls phase  \\\n",
       "0    [https://www.mercedsunstar.com/news/business/a...     E   \n",
       "1    [https://www.lanereport.com/113381/2019/05/qua...     E   \n",
       "2    [http://kstp.com/news/riverview-corridor-proje...     E   \n",
       "3    [https://www.timescolonist.com/opinion/op-ed/i...     E   \n",
       "4    [http://www.nashvillescene.com/music/features/...     E   \n",
       "..                                                 ...   ...   \n",
       "608  [http://www.expressnews.com/news/local/article...     E   \n",
       "609  [https://www.straight.com/arts/1232356/verses-...     E   \n",
       "610  [https://www.tpr.org/post/mcnay-hopes-become-n...     E   \n",
       "611  [http://kron4.com/sports/the-big-game/how-regg...     E   \n",
       "612  [https://www.al.com/news/mobile/2019/07/90-mon...     E   \n",
       "\n",
       "                                             sitenames  \\\n",
       "0    [mercedsunstar, sacbee, mynorthwest, lasvegass...   \n",
       "1                                         [lanereport]   \n",
       "2                                               [kstp]   \n",
       "3                                      [timescolonist]   \n",
       "4                                     [nashvillescene]   \n",
       "..                                                 ...   \n",
       "608                                      [expressnews]   \n",
       "609                                         [straight]   \n",
       "610                                              [tpr]   \n",
       "611  [kron4, krqe, wwlp, everythinglubbock, illinoi...   \n",
       "612                                               [al]   \n",
       "\n",
       "                                                domain  \\\n",
       "0    [com, com, com, com, com, com, com, com, com, ...   \n",
       "1                                                [com]   \n",
       "2                                                [com]   \n",
       "3                                                [com]   \n",
       "4                                                [com]   \n",
       "..                                                 ...   \n",
       "608                                              [com]   \n",
       "609                                              [com]   \n",
       "610                                              [org]   \n",
       "611                [com, com, com, com, net, com, com]   \n",
       "612                                              [com]   \n",
       "\n",
       "                                                  tags  \n",
       "0    [[business], [business], [], [], [politics], [...  \n",
       "1                                                 [[]]  \n",
       "2                                                 [[]]  \n",
       "3                                                 [[]]  \n",
       "4                                            [[music]]  \n",
       "..                                                 ...  \n",
       "608                                               [[]]  \n",
       "609                                            [[art]]  \n",
       "610                                       [[art, art]]  \n",
       "611  [[sport], [sport], [sport], [sport], [sport], ...  \n",
       "612                                               [[]]  \n",
       "\n",
       "[613 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filehandler = bz2.open(PATH_OUT, 'rb') \n",
    "dataframe_example = pickle.load(filehandler)\n",
    "dataframe_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad2615",
   "metadata": {},
   "source": [
    "### Without pickle / writing to new json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.read_json(FILE2016, lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    with bz2.open(PATH_OUT, 'wb') as d_file:\n",
    "        for chunk in df_reader:\n",
    "            chunk_cleaned, chunk_length = process_chunk_complete(chunk, 0.5, matchers)\n",
    "            chunk_json = chunk_cleaned.to_json(orient='columns')#, index=False) #write it to pickle file instead\n",
    "            d_file.write((chunk_json+'\\n').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4571d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(DATA_PATH + 'clean-quotes-2019.json.bz2', orient='columns', compression='bz2')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(DATA_PATH + 'clean-quotes-2019.json.bz2', orient='columns', compression='bz2', lines=True, nrows=100)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00510e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.read_json(DATA_PATH + 'clean-quotes-2019.json.bz2', lines=True, compression='bz2', chunksize=1000) as df_reader:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
